{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocessing and data extraction to npy files for model training",
   "id": "c5a3807f44ec5baf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n"
   ],
   "id": "f892adc7cbb62780",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Gives the bbox and label for n-th box",
   "id": "b640f5e9977085e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_string(ref, file_ref):\n",
    "    return \"\".join([chr(c[0]) for c in file_ref[ref]])\n",
    "\n",
    "def get_name(i, file_ref):\n",
    "    names_refs = file_ref[\"digitStruct\"][\"name\"]\n",
    "    name_ref = names_refs[i-1][0]\n",
    "    return read_string(name_ref, file_ref)\n",
    "\n",
    "def get_boxes(img_num, file_ref):\n",
    "    bbox_refs = file_ref[\"digitStruct\"][\"bbox\"]\n",
    "    master_ref = bbox_refs[img_num-1][0]\n",
    "    bbox_data_struct = file_ref[master_ref]\n",
    "    label_refs = bbox_data_struct[\"label\"]\n",
    "    num_of_digits = label_refs.shape[0]\n",
    "\n",
    "    def get_field(field, digit_num):\n",
    "        field_refs = bbox_data_struct[field]\n",
    "\n",
    "        # if only 1 digit in img then refrence is to float\n",
    "        if (field_refs.dtype == np.dtype(\"float64\")):\n",
    "            field_value = field_refs[0][0].astype(\"int16\")\n",
    "        else: # otherwise have to get the that the specific digit_num\n",
    "            field_value = file_ref[field_refs[digit_num][0]][0][0].astype(\"int16\")\n",
    "\n",
    "        return field_value\n",
    "\n",
    "    bboxes_data = []\n",
    "    label_data = []\n",
    "    filepath = 'data/train/' + get_name(img_num, file_ref)\n",
    "    width, height = Image.open(filepath).size\n",
    "\n",
    "    for i in range(num_of_digits):\n",
    "        if height > width:\n",
    "            x = (get_field(\"left\", i) + (height - width) / 2)/ height\n",
    "            y = get_field(\"top\", i) / height\n",
    "            box_height = get_field(\"height\", i) / height\n",
    "            box_width = get_field(\"width\", i) / height\n",
    "        else:\n",
    "            x = get_field(\"left\", i) / width\n",
    "            y = (get_field(\"top\", i) + (width - height) / 2) / width\n",
    "            box_height = get_field(\"height\", i) / width\n",
    "            box_width = get_field(\"width\", i) / width\n",
    "        bbox_data = np.array([x, y, box_height, box_width], dtype='float64')\n",
    "        bboxes_data.append(bbox_data)\n",
    "        label_data.append(get_field(\"label\", i))\n",
    "\n",
    "    bbox_data = np.array([0,0,0,0], dtype='float64')\n",
    "    while len(bboxes_data) < 6:\n",
    "        bboxes_data.append(bbox_data)\n",
    "        label_data.append(0)\n",
    "    return bboxes_data, label_data\n",
    "\n",
    "bbox_num = 1\n",
    "file_ref = h5py.File(\"data/train_digitStruct.mat\", \"r\")\n",
    "filename = get_name(bbox_num, file_ref)\n",
    "box_info, label_info = get_boxes(bbox_num, file_ref)\n",
    "print(filename, box_info, label_info)\n",
    "width2, height2 = Image.open('data/train/1.png').size\n",
    "print(width2, height2)\n",
    "\n",
    "\n",
    "max_digits # was 6 for training dataset -> set this as the max for model\n"
   ],
   "id": "aea6b9fcf549a76c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saves image data to X_train.npy file in data/ directory",
   "id": "e716239fefa9c592"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def save_img_data(save_path, n):\n",
    "    list = []\n",
    "    image = Image.open('data/train/1.png')\n",
    "    image_array = np.array(image)\n",
    "    for i in range(1,n):\n",
    "        name = str(i) + \".png\"\n",
    "        path = 'data/train/' + name\n",
    "        image = Image.open(path)\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.resize_with_pad(image, 128, 128)\n",
    "        image_array = np.array(image) / 255 #shape(height,width,3) - 3 is RGB.\n",
    "        list.append(image_array)\n",
    "    X_train = np.array(list)\n",
    "    np.save(save_path, X_train)\n",
    "\n",
    "save_img_data(\"data/X_train.npy\", 33403)"
   ],
   "id": "48065ae4e73fb09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saves training bounding box label data to y_train.npy file in data/ directory",
   "id": "3d78f4479d8c243d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#Array of bounding boxes for each image\n",
    "#TODO maybe each array element should have a value for image name.\n",
    "def save_labels(save_path_bboxes, save_path_labels, n, file_ref):\n",
    "    bbox_array = []\n",
    "    labels_array = []\n",
    "    for i in range(1, 33403):\n",
    "        bboxes, labels = get_boxes(i, file_ref)\n",
    "        bbox_array.append(bboxes)\n",
    "        labels_array.append(labels)\n",
    "    y_train = np.array(bbox_array)\n",
    "    np.save(save_path_bboxes, y_train)\n",
    "    labels_train = np.array(labels_array)\n",
    "    np.save(save_path_labels, labels_train)\n",
    "\n",
    "\n",
    "save_labels(\"data/y_train.npy\",\"data/labels_train.npy\", 33403, file_ref)\n",
    "\n"
   ],
   "id": "ae5c92cc09bd763b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This displays images and the bounding boxes of the digits (1-500 checked), need to put bad images in bad_data",
   "id": "1581eaa372e32e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "def visualize_fixed_bboxes(image_dir, y_train, num_show, rows, cols):\n",
    "    \"\"\"\n",
    "    Loads images and displays them with matplotlib bounding boxes, handling\n",
    "    NORMALIZED [Left, Top, Height, Width] format by swapping H and W for plotting.\n",
    "    \"\"\"\n",
    "    image_files = sorted(\n",
    "        [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))],\n",
    "        key=lambda x: int(os.path.splitext(x)[0]) if os.path.splitext(x)[0].isdigit() else x\n",
    "    )\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"Error: No images found in {image_dir}\")\n",
    "        return\n",
    "\n",
    "    num_show = min(num_show, len(image_files), len(y_train))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_show):\n",
    "        try:\n",
    "            # 1. Load the Image and get dimensions\n",
    "            img_path = os.path.join(image_dir, image_files[i])\n",
    "            image = Image.open(img_path)\n",
    "            image_array = np.array(image)\n",
    "\n",
    "            ax = axes[i]\n",
    "\n",
    "            ax.imshow(image_array)\n",
    "\n",
    "            boxes_for_image = y_train[i]\n",
    "\n",
    "            width, height = image.size\n",
    "            max_length = max(width, height)\n",
    "\n",
    "            # --- Calculate Padding Offsets ---\n",
    "            # These offsets are needed to convert from the 'squared' normalized space\n",
    "            # back into the original image's coordinate system.\n",
    "            pad_x = 0\n",
    "            pad_y = 0\n",
    "\n",
    "            if height > width:\n",
    "                # Image was padded horizontally (left/right)\n",
    "                pad_x = (height - width) / 2\n",
    "            elif width > height:\n",
    "                # Image was padded vertically (top/bottom)\n",
    "                pad_y = (width - height) / 2\n",
    "\n",
    "            # The normalization factor is the max dimension\n",
    "            # max_length is already correctly calculated as max(width, height)\n",
    "\n",
    "            for bbox in boxes_for_image:\n",
    "                # The format in y_train is: [L, T, H, W]\n",
    "                normalized_left, normalized_top, normalized_height, normalized_width = bbox\n",
    "\n",
    "                if np.sum(bbox) == 0:\n",
    "                    continue\n",
    "\n",
    "                # --- RESCALE COORDINATES AND REMOVE PADDING OFFSET ---\n",
    "\n",
    "                # 1. Rescale by multiplying by the normalization factor (max_length)\n",
    "                left_rescaled = normalized_left * max_length\n",
    "                top_rescaled = normalized_top * max_length\n",
    "\n",
    "                # 2. Subtract the padding offset to get coordinates in the original image space\n",
    "                left_pixel = left_rescaled - pad_x\n",
    "                top_pixel = top_rescaled - pad_y\n",
    "\n",
    "                # 3. Rescale Dimensions (dimensions do not have padding offset applied)\n",
    "                pixel_width = normalized_width * max_length\n",
    "                pixel_height = normalized_height * max_length\n",
    "\n",
    "                # 4. Create the Matplotlib Bounding Box Patch (W, H are already correct from y_train)\n",
    "                # Matplotlib requires (Left, Top, Width, Height)\n",
    "                rect = patches.Rectangle(\n",
    "                    (left_pixel, top_pixel), # Top-Left corner (NOW CORRECTED)\n",
    "                    pixel_width,             # Width\n",
    "                    pixel_height,            # Height                    linewidth=2,\n",
    "                    edgecolor='blue',\n",
    "                    facecolor='none'\n",
    "                )\n",
    "\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "            ax.set_title(f\"Image: {image_files[i]}\\n(L, T, H, W format)\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process image {image_files[i]}: {e}\")\n",
    "\n",
    "    # Hide any unused subplots if num_show is less than ROWS * COLS\n",
    "    for j in range(num_show, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "NUM_IMAGES_TO_SHOW = 50\n",
    "IMAGE_DIR = 'data/train/'\n",
    "COLS = 5\n",
    "ROWS = int(np.ceil(NUM_IMAGES_TO_SHOW / COLS))\n",
    "y_train = np.load(\"data/y_train.npy\", allow_pickle=True)\n",
    "print(f\"Attempting to display {NUM_IMAGES_TO_SHOW} images from {IMAGE_DIR} with normalized bboxes...\")\n",
    "visualize_fixed_bboxes(IMAGE_DIR, y_train, NUM_IMAGES_TO_SHOW, ROWS, COLS)"
   ],
   "id": "af825cb2ed12aff1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below doesnt work yet",
   "id": "2c70a3c291a580fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import keras\n",
    "# Assuming your model file is named 'my_model.keras'\n",
    "model_path = 'models/svhnModel.keras'\n",
    "\n",
    "# Load the model\n",
    "loaded_model = keras.models.load_model(model_path)\n",
    "\n",
    "# You can now use the model\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "# loaded_model.summary()\n",
    "\n",
    "data_X_test = np.load(\"data/X_test.npy\", allow_pickle=True)\n",
    "data_y_test = np.load(\"data/y_test.npy\", allow_pickle=True)\n",
    "data_labels_test = np.load(\"data/labels_test.npy\", allow_pickle=True)\n",
    "print(data_X_test.shape)\n",
    "print(data_y_test.shape)\n",
    "print(data_labels_test.shape)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((data_X_test, {\"bboxes\": data_y_test, \"classes\": data_labels_test}))\n",
    "ds_test = ds_test.batch(64).prefetch(tf.data.AUTOTUNE)\n"
   ],
   "id": "471649d054b472aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = model.evaluate(ds_test)\n",
    "print(results)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (results[2], results[4]))\n",
    "data_X_test = None\n",
    "data_y_test = None\n",
    "data_labels_test = None\n",
    "ds_test = None\n"
   ],
   "id": "bd595ba1761de52b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
